{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting GPT-4 to write a UI to interact with itself\n",
    "\n",
    "ChatGPT Plus allows users to upload images for analysis, but I am still on the wait list. Therefore, I had ChatGPT write me the code for a Streamlit app that would let me do this on my own.\n",
    "\n",
    "I wrote the below code to interact with ChatGPT and then used the code to interact with ChatGPT, passing it the code itself and asking it to create a UI based off of it. You can see the contents of our conversation below, and the final resulting Streamlit app in `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Function to base-64 encode images\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "class ChatBot:\n",
    "  \n",
    "    def __init__(self, \n",
    "                 api_key=os.getenv('OPENAI_API_KEY'), \n",
    "                 model='gpt-4-vision-preview', \n",
    "                 system='You are a helpful assistant.') -> None:\n",
    "        self._api_key = api_key\n",
    "        self._model = model\n",
    "        self._system = system\n",
    "\n",
    "        self._messages = []\n",
    "        self._max_tokens = 2000\n",
    "\n",
    "    @property\n",
    "    def _headers(self):\n",
    "        return {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self._api_key}\"\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _payload(self):\n",
    "        return {\n",
    "            \"model\": self._model,\n",
    "            \"messages\": self.messages,\n",
    "            \"max_tokens\": self._max_tokens\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def messages(self):\n",
    "       return self._messages\n",
    "    \n",
    "    def clear_messages(self):\n",
    "       self._messages = []\n",
    "\n",
    "    def _add_message(self, message):\n",
    "       self._messages.append(message)\n",
    "\n",
    "    def _ask_text(self, text):\n",
    "        self._add_message(\n",
    "           {\"role\": \"user\", \"content\": text},\n",
    "        )                \n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=self.messages,\n",
    "            max_tokens=self._max_tokens\n",
    "        )\n",
    "\n",
    "        \n",
    "        self._add_message({k: v for (k, v) in response.choices[0].message if k in ['role', 'content']})  \n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _ask_image(self, text, image_path):\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # get response\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self._headers, json=self._payload)\n",
    "        \n",
    "        # add to chat history\n",
    "        self._add_message(m := response.json()['choices'][0]['message'])\n",
    "\n",
    "        return print(m['content'])\n",
    "    \n",
    "    def chat(self, text, image_path=None):\n",
    "       if not image_path:\n",
    "          return self._ask_text(text)\n",
    "       else:\n",
    "          return self._ask_image(text, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a Streamlit app like the one in the provided image, you will need to write a Python script that uses the Streamlit library alongside your `ChatBot` class. Below is an example of how you can create this app. Run this script with Streamlit by saving it to a file (e.g., `app.py`) and then use the command `streamlit run app.py` in your terminal.\n",
      "\n",
      "Please note that the code provided on its own won't work without the correct OpenAI API setup and permissions, as well as ensuring that the `requests` library is imported in the script.\n",
      "\n",
      "```python\n",
      "# Import Streamlit and other necessary libraries\n",
      "import streamlit as st\n",
      "from chat_bot import ChatBot  # Assuming your ChatBot class is in chat_bot.py\n",
      "import tempfile\n",
      "\n",
      "# Set up your Streamlit layout\n",
      "st.title(\"ChatBot with Image Analysis\")\n",
      "\n",
      "# Sidebar for the app\n",
      "st.sidebar.header(\"Upload an Image\")\n",
      "\n",
      "# User can upload an image\n",
      "uploaded_file = st.sidebar.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
      "\n",
      "# Set up columns for input and response\n",
      "col1, col2 = st.columns(2)\n",
      "user_input = \"\"\n",
      "response = \"\"\n",
      "\n",
      "# Run the bot if the image is uploaded\n",
      "if uploaded_file is not None:\n",
      "    # Temporary file workaround for Streamlit's UploadedFile class\n",
      "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
      "        tmp_file.write(uploaded_file.read())\n",
      "        image_path = tmp_file.name\n",
      "    \n",
      "    # Display the uploaded image\n",
      "    col1.header(\"Uploaded Image\")\n",
      "    col1.image(image_path, use_column_width=True)\n",
      "\n",
      "    # Setup the input field and response area\n",
      "    col2.header(\"Input\")\n",
      "    user_input = col2.text_input(\"Ask a question about the image...\")\n",
      "\n",
      "    col2.header(\"Response\")\n",
      "    # ChatBot interaction logic\n",
      "    if user_input:\n",
      "        try:\n",
      "            # Initialize the ChatBot instance\n",
      "            chatbot = ChatBot()\n",
      "            \n",
      "            # Use ChatBot to process the image and text\n",
      "            response = chatbot.chat(user_input.strip(), image_path)\n",
      "\n",
      "            # Display the response\n",
      "            col2.write(response)\n",
      "\n",
      "        except Exception as e:\n",
      "            col2.write(f\"An error occurred: {str(e)}\")\n",
      "\n",
      "else:\n",
      "    col1.write(\"Upload an image to get started.\")\n",
      "```\n",
      "\n",
      "Here are a few things to keep in mind:\n",
      "\n",
      "- The import `from chat_bot import ChatBot` assumes that you've saved the `ChatBot` class definition in a Python file named `chat_bot.py` in the same directory as the Streamlit script.\n",
      "- Streamlit's `file_uploader` returns an object of type `UploadedFile`, which isn't directly usable as a file path. Therefore, the above script writes the uploaded image to a temporary file which the `ChatBot` can work with.\n",
      "- The chatbot response is displayed in `col2` underneath the input.\n",
      "- I have included basic error handling for the chatbot interaction.\n",
      "\n",
      "Make sure Streamlit and any other dependencies are installed in your Python environment (`pip install streamlit`). Then, you can run this app using Streamlit with the `streamlit run app.py` command in your terminal or command prompt.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bot = ChatBot()\n",
    "print(bot.chat(\"\"\"\n",
    "I wrote the following Python code to interact with the OpenAI GPT-4 API:\n",
    "               \n",
    "```python\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Function to base-64 encode images\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "class ChatBot:\n",
    "  \n",
    "    def __init__(self, \n",
    "                 api_key=os.getenv('OPENAI_API_KEY'), \n",
    "                 model='gpt-4-vision-preview', \n",
    "                 system='You are a helpful assistant.') -> None:\n",
    "        self._api_key = api_key\n",
    "        self._model = model\n",
    "        self._system = system\n",
    "\n",
    "        self._messages = []\n",
    "        self._max_tokens = 2000\n",
    "\n",
    "    @property\n",
    "    def _headers(self):\n",
    "        return {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self._api_key}\"\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _payload(self):\n",
    "        return {\n",
    "            \"model\": self._model,\n",
    "            \"messages\": self.messages,\n",
    "            \"max_tokens\": self._max_tokens\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def messages(self):\n",
    "       return self._messages\n",
    "    \n",
    "    def clear_messages(self):\n",
    "       self._messages = []\n",
    "\n",
    "    def _add_message(self, message):\n",
    "       self._messages.append(message)\n",
    "\n",
    "    def _ask_text(self, text):\n",
    "        self._add_message(\n",
    "           {\"role\": \"user\", \"content\": text},\n",
    "        )                \n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=self.messages,\n",
    "            max_tokens=self._max_tokens\n",
    "        )\n",
    "\n",
    "        \n",
    "        self._add_message({k: v for (k, v) in response.choices[0].message if k in ['role', 'content']})  \n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _ask_image(self, text, image_path):\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # get response\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self._headers, json=self._payload)\n",
    "        \n",
    "        # add to chat history\n",
    "        self._add_message(m := response.json()['choices'][0]['message'])\n",
    "\n",
    "        return print(m['content'])\n",
    "    \n",
    "    def chat(self, text, image_path=None):\n",
    "       if not image_path:\n",
    "          return self._ask_text(text)\n",
    "       else:\n",
    "          return self._ask_image(text, image_path)\n",
    "```\n",
    "\n",
    "Write a Python streamlit app that looks like the attached image to allow users to use this code through a GUI\n",
    "\"\"\".strip(),\n",
    "image_path='ui.png'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I understand the issue; the problem occurs because the `_ask_image` method of the `ChatBot` class uses `print` to display the response, which sends the output to the console instead of returning it to the Streamlit interface.\\n\\nTo fix this, you should modify the `_ask_image` method so that it returns the response directly instead of printing it. Here\\'s the corrected version of the `_ask_image` method within the ChatBot class:\\n\\n```python\\n# Inside ChatBot class, modify the _ask_image method\\n\\ndef _ask_image(self, text, image_path):\\n    self.messages.append({\\n        \"role\": \"user\",\\n        \"content\": [\\n            {\"type\": \"text\", \"text\": text},\\n            {\"type\": \"image_url\",\\n             \"image_url\": {\\n                 \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\\n             }\\n            }\\n        ]\\n    })\\n\\n    # get response\\n    response = requests.post(\"https://api.openai.com/v1/chat/completions\",\\n                             headers=self._headers, json=self._payload)\\n\\n    # Check for successful response\\n    if response.status_code == 200:\\n        # add to chat history\\n        self._add_message(m := response.json()[\\'choices\\'][0][\\'message\\'])\\n\\n        return m[\\'content\\']  # Return the message content\\n    else:\\n        raise Exception(\"Error from API: \" + response.text)\\n```\\n\\nAnd in the Streamlit app script, you need to display that returned value in the GUI:\\n\\n```python\\n# Inside the Streamlit app script, after the response is obtained\\n\\nresponse = chatbot.chat(user_input.strip(), image_path)\\ncol2.text_area(\"Response\", response, height=300)\\n```\\n\\nWith these modifications, the response should now show up within the Streamlit GUI in the designated text area instead of the terminal. Remember to save your `ChatBot` class with the modified method before running your Streamlit app again.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"That's close, but the response from the model displays in the terminal rather than the streamlit GUI. Please fix this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand the issue; the problem occurs because the `_ask_image` method of the `ChatBot` class uses `print` to display the response, which sends the output to the console instead of returning it to the Streamlit interface.\n",
      "\n",
      "To fix this, you should modify the `_ask_image` method so that it returns the response directly instead of printing it. Here's the corrected version of the `_ask_image` method within the ChatBot class:\n",
      "\n",
      "```python\n",
      "# Inside ChatBot class, modify the _ask_image method\n",
      "\n",
      "def _ask_image(self, text, image_path):\n",
      "    self.messages.append({\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\"type\": \"text\", \"text\": text},\n",
      "            {\"type\": \"image_url\",\n",
      "             \"image_url\": {\n",
      "                 \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\n",
      "             }\n",
      "            }\n",
      "        ]\n",
      "    })\n",
      "\n",
      "    # get response\n",
      "    response = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
      "                             headers=self._headers, json=self._payload)\n",
      "\n",
      "    # Check for successful response\n",
      "    if response.status_code == 200:\n",
      "        # add to chat history\n",
      "        self._add_message(m := response.json()['choices'][0]['message'])\n",
      "\n",
      "        return m['content']  # Return the message content\n",
      "    else:\n",
      "        raise Exception(\"Error from API: \" + response.text)\n",
      "```\n",
      "\n",
      "And in the Streamlit app script, you need to display that returned value in the GUI:\n",
      "\n",
      "```python\n",
      "# Inside the Streamlit app script, after the response is obtained\n",
      "\n",
      "response = chatbot.chat(user_input.strip(), image_path)\n",
      "col2.text_area(\"Response\", response, height=300)\n",
      "```\n",
      "\n",
      "With these modifications, the response should now show up within the Streamlit GUI in the designated text area instead of the terminal. Remember to save your `ChatBot` class with the modified method before running your Streamlit app again.\n"
     ]
    }
   ],
   "source": [
    "print(bot.messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My apologies for the oversight. This might be happening because the image path created from the temporary file might not be directly usable by Streamlit's `image` function due to differences in how temporary files are handled.\n",
      "\n",
      "To make sure the uploaded image is displayed in the Streamlit GUI, you should read the image into memory and then display it using Streamlit's `image` function without relying on the file path. Here is how you can modify the Streamlit app script to display the uploaded image:\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "from chat_bot import ChatBot  # Assuming your ChatBot class is in chat_bot.py\n",
      "import io\n",
      "\n",
      "# ... your existing Streamlit code ...\n",
      "\n",
      "# Run the bot if the image is uploaded\n",
      "if uploaded_file is not None:\n",
      "    # To read the image into memory\n",
      "    bytes_data = uploaded_file.read()\n",
      "    image_stream = io.BytesIO(bytes_data)\n",
      "    \n",
      "    # Use the PIL library to open the image\n",
      "    from PIL import Image\n",
      "    image = Image.open(image_stream)\n",
      "\n",
      "    # Display the uploaded image\n",
      "    col1.header(\"Uploaded Image\")\n",
      "    col1.image(image, use_column_width=True)\n",
      "\n",
      "    # Setup the input field and response area\n",
      "    col2.header(\"Input\")\n",
      "    user_input = col2.text_input(\"Ask a question about the image...\")\n",
      "\n",
      "    col2.header(\"Response\")\n",
      "    # ChatBot interaction logic will go here\n",
      "\n",
      "    # ... rest of your Streamlit code ...\n",
      "\n",
      "else:\n",
      "    col1.write(\"Upload an image to get started.\")\n",
      "```\n",
      "\n",
      "In this adjusted code:\n",
      "\n",
      "1. Instead of writing the uploaded file to a temporary file, we read the bytes and store them in a `BytesIO` stream.\n",
      "2. Then we use `PIL.Image` to read the image from the `BytesIO` object.\n",
      "3. After that, we can directly supply the `PIL.Image` object to the `st.image` function for display in the Streamlit app.\n",
      "\n",
      "Use this updated script with the previous modifications to your `ChatBot` class. Now, you should see the image displayed in the Streamlit GUI when it is uploaded. Remember to install the Pillow library (`pip install Pillow`) if it's not already installed in your environment, as it's required to work with images in this way.\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"That's good, but the uploaded image does not display in the streamlit GUI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly, you can use `Pillow` directly (which is imported as `PIL`, a historical artifact of when `Pillow` was originally forked from the PIL library). The following code demonstrates how you can display an uploaded image using the `Pillow` library in your Streamlit app:\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "from chat_bot import ChatBot  # Assuming your ChatBot class is in chat_bot.py\n",
      "from PIL import Image\n",
      "import io\n",
      "\n",
      "# ... your existing Streamlit code ...\n",
      "\n",
      "# Run the bot if the image is uploaded\n",
      "if uploaded_file is not None:\n",
      "    # Read the image into a bytes object\n",
      "    bytes_data = uploaded_file.getvalue()\n",
      "    \n",
      "    # Create a BytesIO object from the bytes data and use Pillow to open the image\n",
      "    image = Image.open(io.BytesIO(bytes_data))\n",
      "\n",
      "    # Display the uploaded image in the Streamlit app\n",
      "    col1.header(\"Uploaded Image\")\n",
      "    col1.image(image, use_column_width=True)\n",
      "\n",
      "    # Setup the input field and response area\n",
      "    col2.header(\"Input\")\n",
      "    user_input = col2.text_input(\"Ask a question about the image...\")\n",
      "\n",
      "    col2.header(\"Response\")\n",
      "    if user_input:\n",
      "        # If there is user input, call the chatbot's chat method and pass the bytes_data instead of image path\n",
      "        response = chatbot.chat(user_input, bytes_data=bytes_data)\n",
      "        col2.write(response)\n",
      "\n",
      "else:\n",
      "    col1.write(\"Upload an image to get started.\")\n",
      "```\n",
      "\n",
      "In the Streamlit script above:\n",
      "\n",
      "1. `Pillow` is used to open the image directly from the uploaded file's bytes data.\n",
      "2. The displayed image in the Streamlit app is sourced from the in-memory image object instead of a file path.\n",
      "3. The `ChatBot` class will need to be further modified to accept `bytes_data` as an argument instead of an `image_path`.\n",
      "\n",
      "Modify the `_ask_image` method within the `ChatBot` class to use the bytes data:\n",
      "\n",
      "```python\n",
      "def _ask_image(self, text, bytes_data):\n",
      "    encoded_image = base64.b64encode(bytes_data).decode('utf-8')\n",
      "    self.messages.append({\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\"type\": \"text\", \"text\": text},\n",
      "            {\"type\": \"image_url\",\n",
      "             \"image_url\": {\n",
      "                 \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
      "             }\n",
      "            }\n",
      "        ]\n",
      "    })\n",
      "\n",
      "    # ... the rest of the _ask_image logic to obtain and return the response\n",
      "```\n",
      "\n",
      "Be sure to import the `base64` module and adjust the chat method, so it uses `bytes_data` if provided.\n",
      "\n",
      "Remember that the `ChatBot` class expects the data in a particular format. Make sure that when you're making changes, the data format is consistent with what the `ChatBot` and the API endpoint it communicates with expect.\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"Please use pillow instead of PIL\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
